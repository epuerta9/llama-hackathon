{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os \n",
    "import chromadb\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    QuestionsAnsweredExtractor)\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "from llama_stack_client import AsyncLlamaStackClient\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#kitchenai:GLOBAL_VARS\n",
    "chroma_client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"quickstart\")\n",
    "# client = AsyncLlamaStackClient(\n",
    "#     base_url=f\"http://localhost:5000\",\n",
    "# )\n",
    "client_sync = LlamaStackClient(\n",
    "    base_url=f\"http://localhost:5000\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:storage.file-label\n",
    "\n",
    "parser = Parser(api_key=os.environ.get(\"LLAMA_CLOUD_API_KEY\", None))\n",
    "\n",
    "response = parser.load(dir, metadata=metadata, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-23 15:14:42--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.131.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "--2024-11-23 15:14:42--  http://arxiv.org/pdf/2307.09288\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘data/llama2.pdf’\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  22.6MB/s    in 0.6s    \n",
      "\n",
      "2024-11-23 15:14:43 (22.6 MB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kitchenai:IGNORE\n",
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"\n",
    "from pathlib import Path\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"./data\")\n",
    "response = {}\n",
    "documents = reader.load_data()\n",
    "response[\"documents\"] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 77/77 [00:00<00:00, 373.75it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.53it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.13it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.74s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "100%|██████████| 108/108 [00:40<00:00,  2.69it/s]\n",
      "Generating embeddings: 100%|██████████| 108/108 [00:02<00:00, 49.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7eed53c70190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Store uploaded files into a vector store with metadata\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "        \n",
    "# quickstart index\n",
    "VectorStoreIndex.from_documents(\n",
    "    response[\"documents\"], storage_context=storage_context, show_progress=True,\n",
    "        transformations=[TokenTextSplitter(), TitleExtractor(),QuestionsAnsweredExtractor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:embed.my-embed\n",
    "documents = [Document(text=instance.text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 77/77 [00:00<00:00, 320.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.94it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "100%|██████████| 108/108 [00:41<00:00,  2.59it/s]\n",
      "Generating embeddings: 100%|██████████| 108/108 [00:02<00:00, 42.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7eed539699d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "        \n",
    "VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, show_progress=True,\n",
    "        transformations=[TokenTextSplitter(), TitleExtractor(),QuestionsAnsweredExtractor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarize llama2?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kitchenai:IGNORE\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def __init__(self, query: str):\n",
    "        self.query = query\n",
    "\n",
    "data = Data(\"summarize llama2?\")\n",
    "data.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:query.simple-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is a new family of pretrained and fine-tuned models with scales of 7 billion to 70 billion parameters. It has demonstrated competitiveness with existing open-source chat models and equivalent competency to some proprietary models. However, it still lags behind other models like GPT-4. The methods and techniques applied in achieving these models heavily emphasize alignment with the principles of helpfulness and safety. Llama 2 and Llama 2-Chat have been responsibly opened for access, and there are ongoing commitments to transparency and safety, with plans for further improvements to Llama 2-Chat in future work.\n",
      "\n",
      "Llama 2 comes in a range of parameter sizes—7B, 13B, and 70B—as well as pretrained and fine-tuned variations. It uses an optimized transformer architecture and is trained using supervised fine-tuning and reinforcement learning with human feedback to align to human preferences for helpfulness and safety. It was trained between January 2023 and July 2023 on 2 trillion tokens of data from publicly available sources. The model is intended for commercial and research use in English, with tuned models intended for assistant-like chat and pretrained models adaptable for various natural language generation tasks. However, it should not be used in violation of applicable laws or regulations, in languages other than English, or in any other way prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2.\n"
     ]
    }
   ],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    ")\n",
    "query_engine = index.as_query_engine(chat_mode=\"best\", llm=llm, verbose=True)\n",
    "response = await query_engine.aquery(data.query)\n",
    "\n",
    "print(response.response)\n",
    "#return {\"response\": response.response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:query.no-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no AI is used in this function\n"
     ]
    }
   ],
   "source": [
    "print(\"no AI is used in this function\")\n",
    "\n",
    "#return {\"msg\": \"No AI\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchenai:end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
